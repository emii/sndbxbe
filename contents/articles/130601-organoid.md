Date: 2013-10-26
Title: Image analysis of <em>Organoid</em> primary cell culture
Category: showcase
Tags: research, organoid, image processing, HCI
Summary: Analysis and segmentation of tissue culture organoids
Abstract: Organoids are three-dimensional tissue structures grown in culture from a single adult stem cell of the mouse small intestine. Its shape and physiology resemble the in-vivo situation, which makes them a very suitable model for studying tissue renewal and morphogenesis. Here, timelapse fluorescence microscopy images from the organoid growth were analyzed with state-of-the-art algorithms for cell tracking.  
References: contents/bibtex/Organoid.bib

**Note about figures:** Figures are not displayed. To see the figure please make sure Javascript is enabled, and click on the corresponding link, caption can be unhidden by mouse hover once the image is displayed.

[TOC]

# Introduction
---
Organoids are crypt-villus shaped structures established from long term expansion of self-renewing stems cells of the mouse small-intestine epithelium. In the in-vivo situation for mouse, the small intestine is established from a single layer of cells, and arises from the vigorous proliferation of epithelial tissue around embryonic day 14.5 (E14.5). In later stages, the epithelium is shaped into protrusions (the prospective villi) while cell proliferation is restricted to small compartments which after the third week mature into crypts (E18.5). The native epithelial tissue has a distinctive hierarchical structure where around 15 stem cells reside at the position +4 dividing every 24 hours, other type of cells, the Paneth cells, occupy the positions 1 to 3 from the bottom. Furthermore, stem cells produce rapidly proliferating cells (transit amplifying) which generate 16 to 32 new cell that later stochastically adopt a stem cell fate or differentiate into one mature cell lineage depending on the available space ([Radtke & Clevers 2005](#Radtke2005), [Sato & Clevers 2013](#Sato2013)). Committed cells from neighboring crypts migrate toward one common villus tip, hence, villi origin is said to be polyclonal (Schmidt et al. 1988). In mouse, this tissue is known to have rapid regeneration cycles with a turnover rate of around 5 days where tissue homeostasis is balanced by apoptosis at the tip of the villi. This specific portion of the mouse and also from the human anatomy has been well studied in an effort to understand the process of tissue development and the role of adult stem-cells in regeneration (see <b><a class="fancybox" rel="organoid" data-title-id="caption-1" href="/static/images/organoid/villus-crypt.png" title="click to enlarge">Figure 1</a></b>). 
<div class="img-print"><img src="/static/images/organoid/villus-crypt.png" alt="click to enlarge"/></div>
<div id="caption-1" class="caption-print"><b>Figure 1. Anatomy of the crypt-villus structure in the adult small intestine. </b>Villi are formed from the differentiation (green) and migration of cells proliferating (light blue) in the crypt domain. Cells with stem cell properties (dark blue) reside above Paneth cells (yellow) near the crypt bottom. (image from [Reya & Clevers 2005](#Reya2005))</div>

In recent years, the establishment of advanced culture systems enabling the long term expansion and preservation of the basic physiology of tissues has allowed the isolation of complex three-dimensional structures like the crypt-villus epithelium. Such an ex-vivo system permits for a more controlled experimental setup while characteristics that resemble the native gut environment are maintained, for example: i) stem-cell hierarchy and self renewal, ii) cell type composition, and iii) multi-domain architecture ([Sato et al. 2009](#Sato2009)). It has been proven that these self-organizing structures arise not only from entire isolated crypts but from single stem cells ([Barker et al. 2007](#Barker2007)). In short, organoids constitute an ideal ex-vivo model for the understanding the key events underlying the tissue regeneration and morphogenesis (see <b><a class="fancybox" rel="organoid" data-title-id="caption-2" href="/static/images/organoid/organoid-growth2.png" title="click to enlarge">Figure 2</a></b>).
<div class="img-print"><img src="/static/images/organoid/organoid-growth2.png"/></div><div id="caption-2" class="caption-print"><b>Figure 2. Organoids basic culture system.</b> **A.** Cells from the mouse crypt are enzymatically segregated and Lgr5$^+$ (fluorescent marker) cells are sorted (FACS) and embedded in _Matrigel_ culture medium containing growth factors: EGF, Noggin, and R-spondin **B.** A single cell grows to initially for a spherical shaped cell layer. Later, the symmetrical shape is broken by the growth of a protrusion. Lgr5$^+$ cells (in yellow) interact with Paneth cells (blue) to initiate the bud formation. (image from [Sato & Clevers 2013](#Sato2013)).</div>

## Developmental phenotypes through imaging

The process in which a tissue acquires its shape and identity requires knowledge of the dynamical processes in which the behavior of a cell (as a developmental unit) responds to neighboring signals in a controlled manner. Both spatial and temporal events should be recorded to finally achieve an integrated picture of morphogenesis, covering important cues from the single to the tissue level. Both imaging technologies and computational tools currently provide mechanisms in which development up to the single cell resolution can be achieved. 

Relatively new microscopy techniques aiming for live imaging of entire embryos have overcome the limitations of previous imaging methods (as Laser scanning microscopy, LSM). Speed and depth limits are increased as well as photobleaching and phototoxcicity are reduced simply by orthogonal structured illumination and parallel acquisition of entire micrometer thin volumes ([Huisken et al. 2004](#Huizken2004), [Keller et al. 2008](#Keller2008)). The continuous development of platforms based on selective-plane-illumination-microscopy (SPIM), introduced to biology in 2004 ([Huisken et al. 2004](#Huizken2004)) together with fluorescent markers allows the continuous monitoring of the morphogenesis of entire embryos up to several days with minimal disruption.

Great amount of imaging data is generated continuously, likewise algorithms capable of handling that information are improving. The quantitative data analysis of time-lapse recording demands a simple automated, efficient and robust computational solution. While the first efforts for segmentation and tracking of single GFP stained cell-nuclei required more than 4000 cores of computational power ([Keller et al. 2008](#Keller2008)), today's solutions can be boiled down to a single multi-core personal computer ([Kausler et al. 2012](#Kausler2012), [Schiegg et al. 2013](#Schiegg2013)). With the help of these algorithms, a typical 3D + time dataset can thus be segmented, cell identities can be tracked and cell behavior can be systematically analyzed throughout development (see <b><a class="fancybox" rel="organoid" data-title-id="caption-3" href="/static/images/organoid/quantitative-workflow.png" title="click to enlarge">Figure 3</a></b>).
<div class="img-print"><img src="/static/images/organoid/quantitative-workflow.png"/></div>
<div id="caption-3" class="caption-print"><b>Figure 4. Image based study of morphogenesis. </b>**A.** Various kinds of quantitative information can be extracted from time-lapse image data like: **B.** i) Expression from proliferation, cell-death or cell-type specific makers, ii) division events, or iii) spatial arrangements. These measurements are then translated into a description of various biological processes as lineage tree, tissue renewal/proliferation, morphology/shape architecture. **C.** Measurements from multiple experiments can be compared for between each cell. For example, the comparison of mutant vs. the wild-type where measurements above the wild-type mean are in red while measurements below are in blue.  (image from [Moore et al. 2013](#Moore2013)).</div>

Here we employ an updated version of _[ILASTIK](http://ilastik.org)_ &mdash;an interactive learning, segmentation and tracking toolkit&mdash; ([Sommer et al. 2011](#Sommer2011)) to the multidimensional analysis of spinning disc confocal microscopy recordings of the organoid tissue culture (see **[Figure 6a](#figure-6)**).

##Motivation

Knowledge acquisition of the mechanical, biochemical and temporal cues of the organoids will provide more insight into the self-organizing principles of development, specially of organogenesis and tissue morphogenesis. The standardization of a pipeline for temporally tracking spatial arrangements of cells while capturing proliferation events will eventually serve as a platform for functional analysis and further ex-vivo experiments in an isolated setup. In the future the analysis could be applied to knock-out/knock-in mouse strains, as well as to assays in which stimulation with a signaling molecule is induced. For example, the morphogenic response to induction of known developmental signaling pathways as Wnt-$\beta$-Catenin, bone morphogenic protein and Notch pathways ([Reya & Clevers 2005](#Reya2005)).

##Objectives

1. Use _ILASTIK_ for tracking fluorescently stained nuclei of the organoid tissue culture.

## System under investigation

In culture, the organoid (100-250 μm in diameter) three dimensional structure arises from single sorted/selected Lgr5$^+$ cells which by multiple division events, self-organize into an ordered crypt-villus domains ([Barker et al. 2007](#Barker2007)).This architecture is compared to the native small intestine epithelium by the formation of analogous domains (see <b><a class="fancybox" rel="organoid" data-title-id="caption-4" href="/static/images/organoid/organoid-structure.png" title="click to enlarge">Figure 4</a></b>). The complexity of the organization not only encompasses the spatial arrangement but also the cell type distribution along space and time.<div class="img-print"><img src="/static/images/organoid/organoid-structure.png" alt="click to enlarge"/></div>
<div id="caption-4" class="caption-print"><b>Figure 3. The organoid. </b> **d.** Lgr5$^+$ cells (green) on the tip of the analogous structures to the mouse small-intestine crypts in a three-dimensional reconstruction of confocal microscopy images. **e.** Schematic representation of the organoid with its analogous domains: the crypt, and the villus-like epithelium facing the internal lumen. (from [Moore et al. 2013](#Moore2013)).</div> 

Organoids were genetically manipulated to incorporate a cassette with _C-terminal tagEGFP-IRES:neo_ flanked by loxP recombination sites, the vector was designed for driving H2A-EGFP fusion and the integration of (neo)mycine resistance marker for selection with G418 ([Schwank et al. 2013](#Schwank2013)). During growth, time-lapse recordings of the organoid fluorescently stained nuclei were performed using a spinning disc microscope.

#Experimetal Approach
---
## Organoid primary culture preparation

_**Methods remarks:** As described in [Sato et al. 2009](#Sato2009) and in [Schwank et al. 2013](#Schwank2013), here both culture expansion and imaging were performed by Gerald Schwank_

Crypts were released from murine small intestine in PBS/EDTA. Single crypts were mixed and plated in Matrigel (BDBioscience) in 24-well plates. After polymerization, Matrigel was supplemented with crypt culture medium containing growth factors (EGF, R-spondin, and Noggin).

Single crypts were cultured for two generations under conditioned medium enriching for stem cells. The resulting organoids were mechanically dissociated and trypsinized to obtain single cells. Dissociated cells were collected in culture medium and embedded in Matrigel supplemented with growth factors at 1 cell per well (in 96-well plates).

Organoids were directly genetically manipulated either by electroporation or by liposome-mediated transfection. Both methods were used to transfect organoids with the histone H2A-GFP BAC. After two days, stable clones were selected for G814 resistance as well as for ubiquitious expression of H2A-GFP.

## Image acquisition

After selection and conditioned medium removal, sphere-like organoids started to shape into crypt-villus domains. Imaging started 24h upon the first bud event for most of the organoids.

All images were acquired at 40× magnification (high numerical aperture objective) on a confocal PerkinElmer Ultraview VoX spinning disk microscope equipped with a high-resolution charge-coupled device (CCD) camera and controlled by Volocity software.

At each time point (20 minutes interval), we sequentially acquired three-dimensional stacks of fluorescence images for GFP (H2A-EGFP). Our exposure times were roughly 200 ms. The pixel size was 0.32μm, and the spacing between consecutive planes in our stacks was 1.0 μm yielding an anisotropic voxel size. Organoid evolution was followed up to 48 hours.

#Results and discussion
---

## Image analysis

After image acquisition, images were cropped in XY to a bounding box covering the organoid by its totality. Moreover the image stack was cropped in Z, as depth-dependent intensity and contrast were reduced &mdash;as the far-most plane was reached&mdash; due to photon scattering and the limited penetration capacity of the confocal system. The typical workflow for tracking starts by the segmentation, where pixels are classified as background or foreground. Then, collective movements are adjusted by cross correlation which serves as a preprocessing step for tracking. After single objects are identified, 2 classifiers learn from the manual labeling of division and merge events. Finally trajectories of each cell are assigned and merging events resolved (see **Figure 5**).

<a class="fancybox" rel="organoid" href="/static/images/organoid/image-analysis_workflow.png" title="organoid"><img src="/static/images/organoid/image-analysis_workflow.png" style="background-color:#fff; max-width: 60%; max-height: 400px;" alt="org9" /></a>
<p class="caption" style="width: 60%;"><b>Figure 5. _ILASTIK_ workflow</b> Raw data is segmented into background and foreground from which the objects are extracted. Collective movement is used to adjust object displacements by patch-wise cross correlation. Object classification for division and merger events determine unary potentials later used to solve the proposed factor graph and find a globally consistent tracking solution. Detections identified as possible mergers are resolved in a las step. (scanned from a printed draft for [Schiegg et al. 2013](#Schiegg2013))</p>

### Segmentation

In our particular case, the main objective was the three dimensional segmentation, hence, to classify each pixel either as foreground (fluorescently labeled nuclei) or as background. For this propose, _ILASTIK_ uses a special kind of decision trees, called random forests ([Breiman 2001](#Breiman2001)). Decision trees are a tool used in machine learning to predict the membership of objects &mdash;in this case pixels&mdash; on a determined class &mdash; in this case foreground or background &mdash;. 

In a tree, a path from the root, to a leaf, represents classification rules learned from categorical dependent variables (i.e.foreground, background) measured from one or more predictor variables (features, like intensity, edge and texture). For our binary partition, measurements of features like intensity, edge and texture descriptors for each class were learned by the manual labeling (brush strokes) of a small set of regions, afterward, a random forest classifier is trained with the input labels (see **Figure 6b**).

Each classification tree in the random forest classifier is built form a bootstrap sample of the training data (sampling with replacement). The prediction for each pixel is then classified given the mode of the collect output of the random forest (100 decision trees).

The features where selected by visual inspection such that each of them reveled or enhanced relevant features which provide informative hints for the segmentation of each class. Likewise, as _ILASTIK_ provides means for interactive learning, the manual classification was fine-tuned until foreground regions resembled in shape that of the nuclei and the regions in between nuclei were classified as background.

For the computation of the features, the parameters for the default algorithm were modified to process anisotropic data. For our voxel size, the settings were adapted to support a scale of 1:1:3 (x:y:z).

### Object extraction and classification

From the previously described task we obtained a prediction for the membership of a pixel in its assigned class which we later thresholded to 0.5 for the foreground segmented objects (see **Figure 6c**). We proceeded with object extraction, in this step the connected components were identified and assigned an id for use in later steps (see **Figure 6d**). Here we extracted an average of 228 objects in each time step. 

Before the final tracking step, prior learning for both the division detection classifier and the cell classifier is performed. In the former, cells identified as dividing were labeled in the time step before division, as well, cells not dividing can be labeled. In both cases around 10 objects were assigned a class. We also labeled for misidentified or under-segmented objects which will provided the local evidence for later resolving mergers (see **Figure 6e** ). 


<a id="figure-6"class="fancybox" rel="organoid" href="/static/images/organoid/ilastik_main_2.png" title="organoid"><img class="album-item" src="/static/images/organoid/ilastik_main_2.png" style="background-color:#fff; max-width: 210px; margin-left: 5px;" alt="org1" /></a>
<a class="fancybox" rel="organoid" href="/static/images/organoid/ilastik_training.png" title="organoid"><img class="album-item" src="/static/images/organoid/ilastik_training.png" style="background-color:#fff; max-width: 210px; margin-left: 5px;" alt="org1" /></a>
<a class="fancybox" rel="organoid" href="/static/images/organoid/ilastic_predictions.png" title="organoid"><img class="album-item" src="/static/images/organoid/ilastic_predictions.png" style="background-color:#fff; max-width: 210px; margin-left: 5px;" alt="org1" /></a>
<a class="fancybox" rel="organoid" href="/static/images/organoid/ilastik_object_extraction_2.png" title="organoid"><img class="album-item" src="/static/images/organoid/ilastik_object_extraction_2.png" style="background-color:#fff; max-width: 210px; margin-left: 5px;" alt="org1" /></a>
<a class="fancybox" rel="organoid" href="/static/images/organoid/ilastik_cell_class.png" title="organoid"><img class="album-item" src="/static/images/organoid/ilastik_cell_class.png" style="background-color:#fff; max-width: 210px; margin-left: 5px;" alt="org1" /></a>
<p class="caption" id="caption-6" style="width: 90%;"><strong>Figure 6. Segmentation and Tracking with ILASTIK. </strong>**a.** The hyperstack of three-dimensional images of the organoid were loaded into _ILASTIK_. **b.** Both foregorund (green) and backgorund (red) were manually labeled on a small set of regions ( mouse cursor is also shown in green) **c.** After segmentation we obtained prediction maps which we  later thresholded for foreground objects **d.**  After thresholding connected components were identified and assigned an individual identifier (randomly color-labeled) **e.** Cell classification step, prior to tracking. Misidentified, single and merged objects were manually assigned a class (single cells in green, merger events of two cells in yellow).</p>


### Tracking

Tracking is intended for means to record the trajectory of an object over time. Our targets were the cells identified by the fluorescently labeled nuclei, later segmented. The problem is to find a configuration of cell trajectories which explains better the transitions of all objects between frames across the whole time-lapse.

The method _ILASTIK_ implements is based on a tracking-by-assignment strategy in which every detection is treated as a potential target itself. This is particularly challenging, since cells are dividing, additionally, they constantly appear and disappear from the field of view ([Schegg et al. 2013](#Schiegg2013)). This problem is approached by probabilistic graphical models which are further restricted to conservation laws for the number of objects in each detection to ensure global consistency of the solution. 

The model associates to each detected object a set of three different variables, _detection variables_, _division variables_ and _transition variables_ (see **Figure 7**). Into the detection variables, the model integrates appearance and disappearance of objects in the segmented image. Both events are penalized with an unary potential calculated with a random forest trained on local features like size of the connected component. Likewise, the division variable uses an unary potential determined by a probabilistic classifier trained with local evidence from the interactive labeling of dividing cells. Transition variables indicate the number of objects which are assigned to the transition of another object. Detections (an object upon assignation across all time steps) are handled simultaneously in the holistic graphical model on which inference is performed globally ([Scheigg et al. 2013](#Schiegg2013)) afterward, object merging is approached with Gaussian mixture models.

<a class="fancybox" rel="organoid" href="/static/images/organoid/tracking-hypotesis.png" title="click to enlarge"><img src="/static/images/organoid/tracking-hypotesis.png" style="background-color:#fff; max-width: 60%; max-height: 400px;"/></a>
<p class="caption" style="width: 60%;"><b>Figure 7. Tracking-by-assignment model used in _ILASTIK_. </b> For each detection, different events are considered given the objects (green) association through time. The factor graphs of each event at time t are characterized by three detection variables. Together they account for appearance, vanishing, merging and division events. (scanned from a printed draft for [Schiegg et al. 2013](#Schiegg2013))</p>

As cells might move at with different velocities and/or cells can undergo collective movement, object movement is adjusted in a preprocessing step using patch-wise cross correlation in order to prevent bias towards slow moving objects, additionally this also accounts for small variations in imaging due to the microscope stage drift.

For the analysis of this particular dataset (see **Figure 8**) we went though several rounds of trial and error both for the pixel classification training step, as well as for the parameter selection for the dis/appearance penalty. Finally we set the parameters of B<sub>o</sub> to 0.5, and the diss/appearance penalty to 500, the remaining parameters were left as default (division and transition parameters). Finally we archived a good segmentation, where just a couple of nuclei continued to be merged, however such cases couldn't be resolved since they appeared late in the time course and remained so until the last time point.

<a class="fancybox" rel="organoid" href="/static/images/organoid/organoid_01.gif" title="organoid"><img src="/static/images/organoid/organoid_01.gif" style="background-color:#fff; max-width: 60%;" alt="org11" /></a>
<p class="caption" style="width: 60%;"><b>Figure 8. Raw image stack. </b>Spinning disc microscopy images of the organoid at different planes at one single time point</p>

Regarding the assignment of trajectories we observed a very low number of correct cases. This is due to the poor time resolution, where abrupt changes are found from one time point to the next, and even by visual inspection it was hard to assign an unambiguous trajectory. Finally, we rendered the results in MATLAB. (see **Figure 9**).

<a class="fancybox" rel="organoid" href="/static/images/organoid/organoid_segmentation.gif" title="organoid"><img src="/static/images/organoid/organoid_segmentation.gif" style="background-color:#fff; max-width: 60%;" alt="org12" /></a>
<p class="caption" style="width: 60%;"><b>Figure 9. Tracking result.</b> The resulting segmentation and tracking (randomly color coded) was rendered with MATLAB. Cell with same identity are the same color, however some color labels cannot be distinguished despite their independent identities due to the assignation process which is random.</p>

### Implementation of an edge-aware penalty function

Here we additionally replaced the design parameters for the appearance and disappearance penalty. From the natural observation that objects that are closer to the edge of the _field-of-view_ (FOV) appear and vanish frequently, we decided to penalize them accordingly. We replaced the default constant parameters with a function aware of the distance of the objects to the edge after a given margin. The function we used is designed such that it returns values between 0 and 1, thus, we can scale a penalty value as a function of the object distance to the edge. In this case we selected a logistic functions which can be further parametrized (B<sub>o</sub>) and yield a function from a family of curves between a line and a step function (see **Figure 10**).

<a class="fancybox" rel="organoid" href="/static/images/organoid/edge_penalty.png" title="click to enlarge"><img src="/static/images/organoid/edge_penalty.png" style="background-color:#fff; max-width: 60%; max-height: 400px;"/></a>
<p class="caption" style="width: 60%;"><strong>Figure 10. Logistic function familly</strong> We used a normalized version of the logistic function: $f(x) = \frac{1}{1 + e^{-B_{o}x}}$ in the domain [-10,10] shifted to have have positive values as input. The penalty for appearance and disappearance is defined as a function of the object localization with respect to the FOV edge. An object has a distance of 0 if is located at the edge and of 1 if it is located at the margin. The penalty function is parametrized by B<sub>o</sub>. Depending on its value the function is linear or a step-liken at the extremes.</p>

#Concluding remarks
---

_ILASTIK_ is capable of segmenting and tracking the organoid dataset. The toolkit required to be specifically fine-tuned to meet the requirements of this particular dataset. The task proved to be difficult, as the results were visually assessed and the the assigned trajectories were not always correct throughout the totality of the time-lapse. Apart from the erratic movements of the organoid within the FOV, we link these misassignments to the fact that the organoid was not imaged as a whole, furthermore, as the contrast decreased along the z-axis, the number of mergers increased. Despite we reduced the number of possible mergers by further cropping the stack, and keeping the high contrast planes, the capacity to prove the consistency of the model was diminished (information was lost) as fewer cells were captured; this resulted in some actual cell nuclei to be classified as misdetections. To reduce misdetection of actual nuclei and  to improve the tracking, we then tried to fine-tune the algorithm by differently penalizing the appearance and disappearance of cells in/out the FOV. We replaced a constant penalty value with a sigmoid function from which steepness parameter can be provided, thus the penalty can be tuned from a smooth to a step function penalty regime. Finally this function was integrated into _ILASTIK_ both in the implementation and in the graphical user interface. The implementation of the new penalty regime for dis/appearances reduced the number of actual nuclei to be assigned as misidentifications, which also improved the tracking capabilities for this specific dataset, however further evaluation should be performed with manual tracking (time consuming). We finally suggest the replacement of the used imaging schema in order to improve both depth and acquisition time. Spinning disk microscopy is already faster in acquisition compared to other LSM methods, however it falls short when imaging samples in the range of hundreds of micrometers like the organoids. We previously discussed the advantages of SPIM and we suggest this approach to be used with the organoids. By meeting the previous suggestion, a better  comparison of wild-type vs perturbation experiments can be reached, further shedding light into the mechanisms of tissue regeneration and organization.

#Aknowledgements
---

In the frame of the Master in biosciences at the University of Heidelberg, this project was carried out from May to June 2013 during a 7 week internship supported by Prof. Fred A. Hamprecht in his group: Multidimensional Image Analysis at the Heidelberg Image Collaboratory. It was supervised by Martin Schiegg from the same group, while the image data was generated by Gerald Schwank from the group of Prof. Hans Clevers at the Hubrecht Institute in Utrecht. I would like to thank Martin and Gerald as well as Prof. Hamprecht for their help, advice, and room for collaboration.